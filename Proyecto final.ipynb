{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**01 - exploración de datos**\n",
        "\n",
        "\n",
        "* Sharid Samantha Madrid Ospina, CC 1001652997\n",
        "\n",
        "\n",
        "**Base de datos:**\n",
        "* [Handwriting Recognition ](https://www.kaggle.com/datasets/landlord/handwriting-recognition/data): El dataset está compuesto por más de 400,000 imágenes de nombres y apellidos escritos a mano, divididos en 206,799 nombres y 207,024 apellidos. Las imágenes están distribuidas en tres conjuntos: entrenamiento, prueba y validación.written_name_test_v2.csv"
      ],
      "metadata": {
        "id": "-bu9LP1CZ85d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMdDChe-wuQk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descargar Dataset"
      ],
      "metadata": {
        "id": "kkaDDrlvwwNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "hC2qPRfkXfWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "metadata": {
        "id": "7wxL33jOXoTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97e7f22-bbdb-44ad-adee-f40d1e9e619f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "igfDokoJXsfP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download 'landlord/handwriting-recognition'"
      ],
      "metadata": {
        "id": "dMEP52UZXxNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2574adf2-d809-485c-8fc3-ac4d18d7bebf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/landlord/handwriting-recognition\n",
            "License(s): CC0-1.0\n",
            "Downloading handwriting-recognition.zip to /content\n",
            "100% 1.26G/1.26G [00:15<00:00, 129MB/s]\n",
            "100% 1.26G/1.26G [00:15<00:00, 84.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip handwriting-recognition.zip"
      ],
      "metadata": {
        "id": "R0kgWjoVYOsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm handwriting-recognition.zip\n",
        "! rm kaggle.json"
      ],
      "metadata": {
        "id": "jnz4z3noY1Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "et5iSQfzyq3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and view data"
      ],
      "metadata": {
        "id": "r5IF-wPxytBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('written_name_train_v2.csv')\n",
        "valid = pd.read_csv('written_name_validation_v2.csv')"
      ],
      "metadata": {
        "id": "uxv9FkSOyp0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Data"
      ],
      "metadata": {
        "id": "TB8o8U-HZNWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(axis=0, inplace=True)\n",
        "valid.dropna(axis=0, inplace=True)"
      ],
      "metadata": {
        "id": "Nm_PWPIiZP3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminando imagenes ilegibles\n",
        "\n",
        "unreadable = train[train['IDENTITY'] == 'UNREADABLE']\n",
        "unreadable.reset_index(inplace = True, drop=True)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i in range(6):\n",
        "    ax = plt.subplot(2, 3, i+1)\n",
        "    img_dir = 'train_v2/train/'+unreadable.loc[i, 'FILENAME']\n",
        "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "    plt.imshow(image, cmap = 'gray')\n",
        "    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
      ],
      "metadata": {
        "id": "dv8rPSjTZUeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[train['IDENTITY'] != 'UNREADABLE']\n",
        "valid = valid[valid['IDENTITY'] != 'UNREADABLE']"
      ],
      "metadata": {
        "id": "sI2haS_jZX4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar si hay algun Identity en minuscula\n",
        "train_test = train.copy()\n",
        "train_test['column1'] =train_test['IDENTITY'].str.islower().all()\n",
        "train_test[train_test['column1'] == True]"
      ],
      "metadata": {
        "id": "H2YpDpqnZeeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convertir todos los Identity a mayuscula\n",
        "train.loc[:,'IDENTITY'] = train.loc[:,'IDENTITY'].str.upper()\n",
        "valid.loc[:,'IDENTITY'] = valid.loc[:,'IDENTITY'].str.upper()\n",
        "\n",
        "# Reiniciar los indicess\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)"
      ],
      "metadata": {
        "id": "ftN7cgcbZdXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and preparing the images for training"
      ],
      "metadata": {
        "id": "weXpTzw_X065"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Se cargan las imagenes a escala de grises con ancho 256 y alto 64.  \n",
        "* El ancho y alto son cortados si la el tamano de la imagen es mayor a 256X64 , en caso contrario la imagen es rellenada con pixeles en blanco hasta llegar a este tamano\n",
        "* Finalmente la imagen se rota en sentido de las manesillas del reloj para que el texto no quede horizontal si no alineado con el eje vertical.\n",
        "* Se normaliza la imagen al rango [0,1]"
      ],
      "metadata": {
        "id": "xYVKNRqLX4Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "    (h, w) = img.shape\n",
        "\n",
        "    final_img = np.ones([64, 256])*255 # Espacios en blanco\n",
        "\n",
        "    # crop\n",
        "    if w > 256:\n",
        "        img = img[:, :256]\n",
        "\n",
        "    if h > 64:\n",
        "        img = img[:64, :]\n",
        "\n",
        "\n",
        "    final_img[:h, :w] = img\n",
        "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"
      ],
      "metadata": {
        "id": "JxrFRFnUYGX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 25000\n",
        "valid_size= 3000"
      ],
      "metadata": {
        "id": "VVMXFUzrYHxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img_dir = 'train_v2/train/'+train.loc[1, 'FILENAME']\n",
        "# image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "# image = preprocess(image)\n",
        "# print(image[103])\n",
        "# image = image/255. # Normalizacion [0,1]\n",
        "# print(image[103])\n",
        "\n",
        "# train_x.append(image)"
      ],
      "metadata": {
        "id": "o5tX5ItYYI7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "\n",
        "for i in range(train_size):\n",
        "    img_dir = 'train_v2/train/'+train.loc[i, 'FILENAME']\n",
        "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "    image = preprocess(image)\n",
        "    image = image/255. # Normalizacion [0,1]\n",
        "    train_x.append(image)"
      ],
      "metadata": {
        "id": "43AE9wXgYKY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_x = []\n",
        "\n",
        "for i in range(valid_size):\n",
        "    img_dir = 'validation_v2/validation/'+valid.loc[i, 'FILENAME']\n",
        "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "    image = preprocess(image)\n",
        "    image = image/255. # Normalizacion [0,1]\n",
        "    valid_x.append(image)"
      ],
      "metadata": {
        "id": "8Sg3gBKMYLzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
        "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"
      ],
      "metadata": {
        "id": "WjteceYkYNKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n",
        "max_str_len = 24 # max length of input labels\n",
        "num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n",
        "num_of_timestamps = 64 # max length of predicted labels\n",
        "\n",
        "\n",
        "def label_to_num(label):\n",
        "    label_num = []\n",
        "    for ch in label:\n",
        "        label_num.append(alphabets.find(ch))\n",
        "\n",
        "    return np.array(label_num)\n",
        "\n",
        "def num_to_label(num):\n",
        "    ret = \"\"\n",
        "    for ch in num:\n",
        "        if ch == -1:  # CTC Blank\n",
        "            break\n",
        "        else:\n",
        "            ret+=alphabets[ch]\n",
        "    return ret"
      ],
      "metadata": {
        "id": "09HkUHSLYO11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#name = 'JEBASTIN'\n",
        "#print(name, '\\n',label_to_num(name))"
      ],
      "metadata": {
        "id": "vmWxliJKYQvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* train_y contiene los valores reales convertido a un arreglo de numeros , el tamano de cada label es igual a max_str_len\n",
        "* train_label_len contiene el tamano del valor real de cada label ( sin relleno )   \n",
        "* train_input_len Contiene el tamano de la prediccion de cada label , el tamano de todas las predicciones es constante\n",
        "* train_output es un  output para  ctc loss."
      ],
      "metadata": {
        "id": "kSR7ekMBYSmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.ones([train_size, max_str_len]) * -1\n",
        "train_label_len = np.zeros([train_size, 1])\n",
        "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n",
        "train_output = np.zeros([train_size])\n",
        "\n",
        "for i in range(train_size):\n",
        "    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n",
        "    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])"
      ],
      "metadata": {
        "id": "9uSU7u8EYVRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_y = np.ones([valid_size, max_str_len]) * -1\n",
        "valid_label_len = np.zeros([valid_size, 1])\n",
        "valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\n",
        "valid_output = np.zeros([valid_size])\n",
        "\n",
        "for i in range(valid_size):\n",
        "    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n",
        "    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])"
      ],
      "metadata": {
        "id": "B5yPNlc3YXa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100],\n",
        "#       '\\ntrain_input_len : ', train_input_len[100])"
      ],
      "metadata": {
        "id": "j55yp_ZCYYru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "JaDTyKevYaqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model"
      ],
      "metadata": {
        "id": "OsTb275kYcc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = Input(shape=(256, 64, 1), name='input')\n",
        "\n",
        "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
        "\n",
        "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "\n",
        "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "\n",
        "# CNN to RNN\n",
        "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
        "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
        "\n",
        "## RNN\n",
        "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n",
        "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n",
        "\n",
        "## OUTPUT\n",
        "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
        "y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "model = Model(inputs=input_data, outputs=y_pred)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "OX1TDStgYaPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La dimension de salida de la prediccion es (64,30) . El modelo predice palabras de 64 caracteres y cada caracter contiene la probabilidad de 30 letras que definimos anteriormente."
      ],
      "metadata": {
        "id": "pAfpJMxdYfiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the ctc loss function\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN\n",
        "    # tend to be garbage\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "metadata": {
        "id": "c5tl8--cYkhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
      ],
      "metadata": {
        "id": "H6STTCDxYpSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "PCa3FTgaYrBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\n",
        "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred},\n",
        "                    optimizer=Adam(lr = 0.0001),\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output,\n",
        "                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n",
        "                epochs=60, batch_size=10)"
      ],
      "metadata": {
        "id": "ltdNRGSaYrnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model performance para el set de validacion"
      ],
      "metadata": {
        "id": "HSBqR8tkYva7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(valid_x)\n",
        "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1],\n",
        "                                   greedy=True)[0][0])\n",
        "\n",
        "prediction = []\n",
        "for i in range(valid_size):\n",
        "    prediction.append(num_to_label(decoded[i]))"
      ],
      "metadata": {
        "id": "pinpXkL6Yw-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = valid.loc[0:valid_size, 'IDENTITY']\n",
        "correct_char = 0\n",
        "total_char = 0\n",
        "correct = 0\n",
        "\n",
        "for i in range(valid_size):\n",
        "    pr = prediction[i]\n",
        "    tr = y_true[i]\n",
        "    total_char += len(tr)\n",
        "\n",
        "    for j in range(min(len(tr), len(pr))):\n",
        "        if tr[j] == pr[j]:\n",
        "            correct_char += 1\n",
        "\n",
        "    if pr == tr :\n",
        "        correct += 1\n",
        "\n",
        "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
        "print('Correct words predicted      : %.2f%%' %(correct*100/valid_size))"
      ],
      "metadata": {
        "id": "SiyKRZvaYyuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algunas predicciones en el set de pruebas"
      ],
      "metadata": {
        "id": "AsuqtHvEY1yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('written_name_test_v2.csv')\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(6):\n",
        "    ax = plt.subplot(2, 3, i+1)\n",
        "    img_dir = 'test_v2/test/'+test.loc[i, 'FILENAME']\n",
        "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "\n",
        "    image = preprocess(image)\n",
        "    image = image/255.\n",
        "    pred = model.predict(image.reshape(1, 256, 64, 1))\n",
        "    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1],\n",
        "                                       greedy=True)[0][0])\n",
        "    plt.title(num_to_label(decoded[0]), fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
      ],
      "metadata": {
        "id": "tH_rLLVfY3pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plt.subplot(2, 3, i+1)\n",
        "img_dir = 'test7.jpg'\n",
        "image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "image = preprocess(image)\n",
        "image = image/255.\n",
        "pred = model.predict(image.reshape(1, 256, 64, 1))\n",
        "decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1],\n",
        "                                    greedy=True)[0][0])\n",
        "plt.title(num_to_label(decoded[0]), fontsize=12)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
      ],
      "metadata": {
        "id": "axKA2g-RY6vY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}